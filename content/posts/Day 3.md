---
title: "Day 3"
date: 2021-06-14T12:02:01+05:30
draft: false
---

Day 3

# Day 3

* Loss
* Gradient Descent
* Learning Rate

Loss is essentially how far from the actual value the model predicted. Loss is higher when the values are farther from the prediction line.

Gradient Descent is a method to minimise loss where you take a Convex Curve got by examining all possible values of loss.

Its an iterative approach where it starts at a point on the curve and it keeps going down and down and down till at one point the loss goes up. That point is the loweest possible loss for the model

Learning Rate means the rate at which the machine learns about a certain problem. Its value is similar to the lowest point from Gradient Descent. 

A small learning rate will take years to train.

A large learning rate will result in more loss than the minimum

There are many ways to reduce loss